\newpage
\section*{Введение}

В радиолокации интересной является задача моделирования распространения электромагнитного сигнала и определение зон, затемененных объектом, а также областей, распространения переотраженного сигнала. Особенно это важно при использовании радиотехнических систем на протяженных объектах, так как возникают дополнительные ошибки измерения радиолокационных параметров, например, при стыковках космических кораблей и работе космических станций \cite{sazonov}. Так при стыковке в зону между принимающей антенны и передающей попадают элементы конструкций, порождая переотражение и искажение сигнала. Возможным решением этой проблемы является выбор зон пространства, в котором такое влияние переотражений минимально.

Целью данной работы является создание программного обеспечения, позволяющее визуализировать распространение сигнала в пространстве и его отражение от сложных полигональных моделей.

Однако, при попытках детального моделирования описанного выше процесса, мы неминуемо приходим к тому, что используемые компьютерные модели космических объектов обладают огромным количеством полигонов, а вычислительных ресурсов даже современных персональных компьютеров не хватает для их обработки. 

Проведем простые предварительные расчеты. Если наша модель содержит 10 000 полигонов, то для того, чтобы  определить, какие грани являются первичными для всей модели нам потребуется обработать порядка $ 10^8 $ полигонов (без алгоритмических оптимизаций, <<влоб>>). Мы же в работе будем использовать модель космического корабля <<Союз>> \cite{soyz}, содержащий 152 000 полигонов. Это число внушительно, просто необходимы большие мощности. Поэтому для расчетов будем использовать вычисления на графических ускорителях и технологию CUDA. 

Графические ускорители выросли из задач обработки и формирования изображения на экране компьютера постепенно переродившись в массивно-параллельные процессоры общего назначения. Сам термин GPU (Graphics Processing Unit) относительно новый и впервые был использован корпорацией Nvidia, в качестве обозначения того, что графические ускорители стали мощными программируемыми устройствами пригодными для решения более широкого класса задач, не связанных с графикой \cite{boreskov1}.

Первые графические ускорители представляли из себя простые растеризаторы, однако эту простую задачу делали быстрее универсального процессора, что и привело к распространению графических ускорителей. Основная причина этого -- ускоритель мог обрабатывать хоть и простую, но зато масштабную работу -- обрабатывать сразу много отдельных пикселов \cite{boreskov1}.

По мере развития функциональность увеличивалась. Фактически графические ускорители стали представлять из себя SIMD-процессоры (Single Instruction Multiple Data), то есть параллельные устройства, способные одновременно выполнять одну и ту же операцию над многими данными. Экспоненциальный рост производительности и функциональности дал развитие направлению GPGPU (General-Purpose computing on Graphics Processing Units). 

Все это открывает новые возможности при реализации приложений, требущих больших объемов специфических вычислений. И если раньше ресурсоемкие задачи и можно было решить, то только с использованием суперкомпьютеров и кластеров, то теперь это представляется возможным на обычном пользовательском  компьютере. 

На сегодняшний день существуют несколько технологий для разработки приложений, использующих для вычислений графические ускорители: OpenCL, CUDA, ATI Stream Technology. В нашей работе мы остановимся на технологии Nvidia CUDA и будем использовать её. 

На то есть несколько причин. Nvidia CUDA хорошо зарекомендовала себя при решении многих ресурсоемких задач: моделирование гидродинамики \cite{berezin}, волн цунами \cite{cynami}, вычисления нейронных сетей \cite{neuron}.


